{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Code Summary\\summarize-torch\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"vinai/phobert-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing BertModel: ['roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.8.attention.self.value.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.embeddings.position_ids', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'lm_head.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "e:\\Code Summary\\summarize-torch\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2357: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,   218,    52,   222,    25,   212,  2919,   222,   385,  8249,\n",
      "             2],\n",
      "        [    0,   218,     8,   277,     2,     1,     1,     1,     1,     1,\n",
      "             1],\n",
      "        [    0,   716,   306, 17591, 18657,  8210,  1517,  1157,  1476,     2,\n",
      "             1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n",
      "torch.Size([3, 11])\n",
      "output odict_keys(['last_hidden_state', 'pooler_output'])\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "config = BertConfig.from_pretrained(\"vinai/phobert-base-v2\", output_hidden_states=True)\n",
    "model = BertModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "\n",
    "inputs = tokenizer([\"Tôi đang học ở trường đại học tự nhiên\", \"Tôi là ai\"], return_tensors=\"pt\", padding=True, max_length=max)\n",
    "inputs2 = tokenizer.batch_encode_plus([\"Tôi đang học ở trường đại học tự nhiên\", \"Tôi là ai\", \"Hai tay bưng dĩa í a bánh bò\"], return_tensors=\"pt\", padding=True, max_length=512, truncation=True, add_special_tokens=True)\n",
    "print(inputs2)\n",
    "print(inputs2['input_ids'].shape)\n",
    "outputs = model(**inputs2)\n",
    "print(\"output\", outputs.keys())\n",
    "print(len(outputs))  # 3\n",
    "\n",
    "hidden_states = outputs['last_hidden_state']\n",
    "print(len(hidden_states))  # 13\n",
    "\n",
    "embedding_output = hidden_states[0]\n",
    "attention_hidden_states = hidden_states[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(64001, 768, padding_idx=1)\n",
      "Embedding(258, 768)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m torchsummary\u001b[39m.\u001b[39;49msummary(model,input_size\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor((\u001b[39m2\u001b[39;49m,\u001b[39m11\u001b[39;49m,)))\n",
      "File \u001b[1;32me:\\Code Summary\\summarize-torch\\.venv\\lib\\site-packages\\torchsummary\\torchsummary.py:60\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     57\u001b[0m     input_size \u001b[39m=\u001b[39m [input_size]\n\u001b[0;32m     59\u001b[0m \u001b[39m# batch_size of 2 for batchnorm\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m x \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mrand(\u001b[39m2\u001b[39m, \u001b[39m*\u001b[39min_size)\u001b[39m.\u001b[39mtype(dtype) \u001b[39mfor\u001b[39;00m in_size \u001b[39min\u001b[39;00m input_size]\n\u001b[0;32m     61\u001b[0m \u001b[39m# print(type(x[0]))\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[39m# create properties\u001b[39;00m\n\u001b[0;32m     64\u001b[0m summary \u001b[39m=\u001b[39m OrderedDict()\n",
      "File \u001b[1;32me:\\Code Summary\\summarize-torch\\.venv\\lib\\site-packages\\torchsummary\\torchsummary.py:60\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m     input_size \u001b[39m=\u001b[39m [input_size]\n\u001b[0;32m     59\u001b[0m \u001b[39m# batch_size of 2 for batchnorm\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m x \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mrand(\u001b[39m2\u001b[39m, \u001b[39m*\u001b[39min_size)\u001b[39m.\u001b[39mtype(dtype) \u001b[39mfor\u001b[39;00m in_size \u001b[39min\u001b[39;00m input_size]\n\u001b[0;32m     61\u001b[0m \u001b[39m# print(type(x[0]))\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[39m# create properties\u001b[39;00m\n\u001b[0;32m     64\u001b[0m summary \u001b[39m=\u001b[39m OrderedDict()\n",
      "File \u001b[1;32me:\\Code Summary\\summarize-torch\\.venv\\lib\\site-packages\\torch\\_tensor.py:1022\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1013\u001b[0m     \u001b[39m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[39m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     \u001b[39m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m     \u001b[39m# See gh-54457\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1022\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39miteration over a 0-d tensor\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1023\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state():\n\u001b[0;32m   1024\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1025\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1026\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPassing a tensor of different shape won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt change the number of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1030\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   1031\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import torch\n",
    "filetrain='train_pharagraph_full.jl'\n",
    "filetarget='target_strings_full.jl'\n",
    "train_pharagraph = joblib.load(filetrain)\n",
    "target_strings = joblib.load(filetarget)\n",
    "\n",
    "targets = []\n",
    "for ele in target_strings:\n",
    "    ele = re.sub(r'[\\W_]', ' ', ele)\n",
    "    ele = re.sub(r'[^\\w\\s]', '', ele)\n",
    "    ele = re.sub(r'\\t\\n', '', ele)\n",
    "    targets.append(ele)\n",
    "\n",
    "training_input = []\n",
    "for ele in train_pharagraph:\n",
    "    ele = re.sub(r'[\\W_]', ' ', ele)\n",
    "    ele = re.sub(r'[^\\w\\s]', '', ele)\n",
    "    ele = re.sub(r'\\t\\n', '', ele)\n",
    "    training_input.append(ele)\n",
    "\n",
    "document = pd.Series(training_input)\n",
    "summary = pd.Series(targets)\n",
    "\n",
    "doc_list = []\n",
    "sum_list = []\n",
    "for index, doc in enumerate(document):\n",
    "    if len(doc) < 2000:\n",
    "        doc_list.append(doc)\n",
    "        sum_list.append(summary[index])\n",
    "\n",
    "document = pd.Series(doc_list)\n",
    "summary = pd.Series(sum_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Code Summary\\summarize-torch\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2357: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "targets = tokenizer(sum_list[:100],  return_tensors=\"pt\", padding=True,max_length=200)\n",
    "inputs = tokenizer(doc_list[:100],  return_tensors=\"pt\", padding=True,max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, inputs,targets):\n",
    "        super().__init__()\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        inp_input_ids = self.inputs['input_ids'][index]\n",
    "        inp_token_type_ids = self.inputs['token_type_ids'][index]\n",
    "        inp_attention_mask = self.inputs['attention_mask'][index]\n",
    "        tar_input_ids = self.targets['input_ids'][index]\n",
    "        tar_token_type_ids = self.targets['token_type_ids'][index]\n",
    "        tar_attention_mask = self.targets['attention_mask'][index]\n",
    "\n",
    "        return {\n",
    "            'inp_input_ids' : inp_input_ids,\n",
    "            'inp_token_type_ids' : inp_token_type_ids,\n",
    "            'inp_attention_mask' : inp_attention_mask,\n",
    "            'tar_input_ids' : tar_input_ids,\n",
    "            'tar_token_type_ids' : tar_token_type_ids,\n",
    "            'tar_attention_mask' : tar_attention_mask,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(inputs, targets)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0, 16894,  3139,   963,  2271,    48,    99,  5330, 11603,     6,\n",
      "           48,   358,   113,    80,     7,  1393,  2075,    24,   273,   123,\n",
      "          188,  2006, 46779,     2])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mprint\u001b[39m(tar_input_ids)\n\u001b[0;32m     27\u001b[0m inp_input_ids,inp_token_type_ids,inp_attention_mask, tar_input_ids \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39minp_input_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device), row[\u001b[39m'\u001b[39m\u001b[39minp_token_type_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device), row[\u001b[39m'\u001b[39m\u001b[39minp_attention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device), row[\u001b[39m'\u001b[39m\u001b[39mtar_input_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 28\u001b[0m train_step( inp_input_ids\u001b[39m.\u001b[39;49mto(device), inp_token_type_ids\u001b[39m.\u001b[39;49mto(device), inp_attention_mask\u001b[39m.\u001b[39;49mto(device), tar_input_ids\u001b[39m.\u001b[39;49mto(device) , transformer, optimizer, scheduler)\n",
      "File \u001b[1;32me:\\Code Summary\\summarize-torch\\main.py:105\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(inp_input_ids, inp_token_type_ids, inp_attention_mask, tar_input_ids, transformer, optimizer, scheduler)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(inp_input_ids, inp_token_type_ids, inp_attention_mask, tar_input_ids, transformer, optimizer, scheduler):\n\u001b[0;32m    104\u001b[0m     tar_real \u001b[39m=\u001b[39m tar_input_ids\n\u001b[1;32m--> 105\u001b[0m     enc_padding_mask, combined_mask, dec_padding_mask \u001b[39m=\u001b[39m create_masks(inp_input_ids, tar_input_ids)\n\u001b[0;32m    106\u001b[0m     predictions, enc_output, att_weights \u001b[39m=\u001b[39m transformer(\n\u001b[0;32m    107\u001b[0m         inp_input_ids, inp_token_type_ids, inp_attention_mask, tar_input_ids, \n\u001b[0;32m    108\u001b[0m         enc_padding_mask, \n\u001b[0;32m    109\u001b[0m         combined_mask, \n\u001b[0;32m    110\u001b[0m         dec_padding_mask,\n\u001b[0;32m    111\u001b[0m     )\n\u001b[0;32m    112\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(tar_real, predictions)\n",
      "File \u001b[1;32me:\\Code Summary\\summarize-torch\\helper.py:116\u001b[0m, in \u001b[0;36mcreate_masks\u001b[1;34m(inp, tar)\u001b[0m\n\u001b[0;32m    114\u001b[0m dec_padding_mask \u001b[39m=\u001b[39m create_padding_mask(inp)\n\u001b[0;32m    115\u001b[0m look_ahead_mask \u001b[39m=\u001b[39m create_look_ahead_mask(tar\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n\u001b[1;32m--> 116\u001b[0m look_ahead_mask \u001b[39m=\u001b[39m look_ahead_mask\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m    117\u001b[0m dec_target_padding_mask \u001b[39m=\u001b[39m create_padding_mask(tar)\n\u001b[0;32m    119\u001b[0m combined_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(dec_target_padding_mask, look_ahead_mask)\n",
      "File \u001b[1;32me:\\Code Summary\\summarize-torch\\.venv\\lib\\site-packages\\torch\\cuda\\__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    289\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m\"\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 293\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from main import *\n",
    "from transform import *\n",
    "word2Topic = joblib.load('word2Topic_v2.jl')\n",
    "list_topic_count = joblib.load('list_topic_count.jl')\n",
    "\n",
    "encoder_vocab_size = tokenizer.vocab_size\n",
    "decoder_vocab_size = tokenizer.vocab_size\n",
    "transformer = TransformerModel(\n",
    "    num_layers, \n",
    "    d_model, \n",
    "    num_heads, \n",
    "    dff,\n",
    "    encoder_vocab_size, \n",
    "    decoder_vocab_size, \n",
    "    pe_input=encoder_vocab_size, \n",
    "    pe_target=decoder_vocab_size,\n",
    "    word2Topic=word2Topic,\n",
    "    list_topic_count=list_topic_count,\n",
    "    bert=model\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "learning_rate = CustomSchedule(optimizer, d_model)\n",
    "logging.info(f\"learning rate - {learning_rate}\")\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: epoch/10)\n",
    "for batch, row in enumerate(dataloader):\n",
    "            print(tar_input_ids)\n",
    "            inp_input_ids,inp_token_type_ids,inp_attention_mask, tar_input_ids = row['inp_input_ids'].to(device), row['inp_token_type_ids'].to(device), row['inp_attention_mask'].to(device), row['tar_input_ids'].to(device)\n",
    "            train_step( inp_input_ids.to(device), inp_token_type_ids.to(device), inp_attention_mask.to(device), tar_input_ids.to(device) , transformer, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "from config import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, inputs,targets):\n",
    "        super().__init__()\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        inp_input_ids = self.inputs['input_ids'][index]\n",
    "        inp_token_type_ids = self.inputs['token_type_ids'][index]\n",
    "        inp_attention_mask = self.inputs['attention_mask'][index]\n",
    "        tar_input_ids = self.targets['input_ids'][index]\n",
    "        tar_token_type_ids = self.targets['token_type_ids'][index]\n",
    "        tar_attention_mask = self.targets['attention_mask'][index]\n",
    "\n",
    "        return {\n",
    "            'inp_input_ids' : inp_input_ids,\n",
    "            'inp_token_type_ids' : inp_token_type_ids,\n",
    "            'inp_attention_mask' : inp_attention_mask,\n",
    "            'tar_input_ids' : tar_input_ids,\n",
    "            'tar_token_type_ids' : tar_token_type_ids,\n",
    "            'tar_attention_mask' : tar_attention_mask,\n",
    "        }\n",
    "\n",
    "# dataset = MyDataset(inputs,targets)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from helper import *\n",
    "from config import *\n",
    "\n",
    "dataset = MyDataset(inputs,targets)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['inp_input_ids', 'inp_token_type_ids', 'inp_attention_mask', 'tar_input_ids', 'tar_token_type_ids', 'tar_attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "for batch, inp in enumerate(dataset):\n",
    "    print(inp.keys())\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loss = []\n",
    "def train_step(inp, tar, transformer, optimizer, scheduler):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    predictions, enc_output, att_weights = transformer(\n",
    "        inp, tar_inp, \n",
    "        True, \n",
    "        enc_padding_mask, \n",
    "        combined_mask, \n",
    "        dec_padding_mask,\n",
    "    )\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "        print(\"Epoch {}\".format(epoch))\n",
    "        train_loss.clear()\n",
    "        for batch, row in enumerate(dataset):\n",
    "            train_step( {key: row[key] for key in row.keys() if 'inp' in key}, {key: row[key] for key in row.keys() if 'tar' in key}, transformer, optimizer, scheduler)\n",
    "            if batch > 0 and batch % 1000 == 0:\n",
    "                print('Batch {} Loss {:.4f}'.format(batch, sum(train_loss) / len(train_loss)))\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch, sum(train_loss) / len(train_loss)))\n",
    "        print('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "        if (epoch > 0 and epoch % 15 == 0):\n",
    "            torch.save(transformer.state_dict(), f\"checkpoints/transformer_epoch_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([999, 11])\n",
      "torch.Size([999, 1])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = torch.randn(999, 11, dtype=torch.float32)\n",
    "targets_1 = torch.randint(5, (999, 1), dtype=torch.long)\n",
    "print(inputs_1.shape)\n",
    "print(targets_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
